import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the dataset
data_path = 'HW1.csv'
data = pd.read_csv(data_path)

# Display the first few rows of the dataset
print(data.head())
print(data.columns)

# Gradient Descent Implementation
def gradient_descent(X, Y, learning_rate=0.01, iterations=1000):
    m = len(Y)
    theta0 = 0
    theta1 = 0
    cost_history = []

    for _ in range(iterations):
        # Predictions
        y_pred = theta0 + theta1 * X

        # Cost
        cost = (1/(2*m)) * np.sum((y_pred - Y) ** 2)
        cost_history.append(cost)

        # Gradients
        d_theta0 = (1/m) * np.sum(y_pred - Y)
        d_theta1 = (1/m) * np.sum((y_pred - Y) * X)

        # Update parameters
        theta0 -= learning_rate * d_theta0
        theta1 -= learning_rate * d_theta1

    return theta0, theta1, cost_history

# Plotting function
def plot_results(X, Y, theta0, theta1, cost_history, variable_name):
    plt.figure(figsize=(12, 5))

    # Plot regression
    plt.subplot(1, 2, 1)
    plt.grid(True)
    plt.scatter(X, Y, color='blue', label='Data points')
    plt.plot(X, theta0 + theta1 * X, color='red', label='Fitted line')
    plt.title(f'Regression Line for {variable_name}')
    plt.xlabel(variable_name)
    plt.ylabel('Y')
    plt.legend()
    plt.grid(True)

    # Plot cost
    plt.subplot(1, 2, 2)
    plt.grid(True)
    plt.plot(range(len(cost_history)), cost_history, color='green')
    plt.title(f'Loss over Iterations for {variable_name}')
    plt.xlabel('Iterations')
    plt.ylabel('Loss')
    plt.yscale('log')

    plt.tight_layout()
    plt.show()

# Parameters for the model
learning_rates = [0.01, 0.05, 0.1]
iterations = 1000

# Run gradient descent for X1
results_X1 = []
for lr in learning_rates:
    theta0, theta1, cost_history = gradient_descent(data['X1'], data['Y'], learning_rate=lr, iterations=iterations)
    results_X1.append((theta0, theta1, cost_history, lr))
    plot_results(data['X1'], data['Y'], theta0, theta1, cost_history, 'X1')

# Run gradient descent for X2
results_X2 = []
for lr in learning_rates:
    theta0, theta1, cost_history = gradient_descent(data['X2'], data['Y'], learning_rate=lr, iterations=iterations)
    results_X2.append((theta0, theta1, cost_history, lr))
    plot_results(data['X2'], data['Y'], theta0, theta1, cost_history, 'X2')

# Run gradient descent for X3
results_X3 = []
for lr in learning_rates:
    theta0, theta1, cost_history = gradient_descent(data['X3'], data['Y'], learning_rate=lr, iterations=iterations)
    results_X3.append((theta0, theta1, cost_history, lr))
    plot_results(data['X3'], data['Y'], theta0, theta1, cost_history, 'X3')

# Extracting the minimum loss for each variable at learning rate 0.05 (index 1 for each result)
min_loss_X1 = min(results_X1[1][2])
min_loss_X2 = min(results_X2[1][2])
min_loss_X3 = min(results_X3[1][2])

print(f"Minimum loss for X1: {min_loss_X1}")
print(f"Minimum loss for X2: {min_loss_X2}")
print(f"Minimum loss for X3: {min_loss_X3}")
#Problem 2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('HW1.csv', header=None)

# Convert all data to numeric, coerce errors to NaN, then fill NaNs with the column mean
data = data.apply(pd.to_numeric, errors='coerce')
data = data.fillna(data.mean())

# Separate explanatory variables (X) and the dependent variable (y)
X = data.iloc[:, 0:3].values
y = data.iloc[:, 3].values

# Standardize the features and the target variable
from sklearn.preprocessing import StandardScaler
scaler_X = StandardScaler()
scaler_y = StandardScaler()
X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()

# Define hypothesis function
def hypothesis(theta, X):
    return np.dot(X, theta)

# Define cost function
def cost_function(theta, X, y):
    m = len(y)
    return (1/(2*m)) * np.sum((hypothesis(theta, X) - y) ** 2)

# Implement gradient descent
def gradient_descent(X, y, theta, learning_rate, iterations):
    m = len(y)
    cost_history = []
    
    for i in range(iterations):
        theta = theta - (learning_rate/m) * np.dot(X.T, (hypothesis(theta, X) - y))
        cost = cost_function(theta, X, y)
        if np.isnan(cost):
            print(f"NaN at iteration {i}: theta = {theta}")
            break
        cost_history.append(cost)
        
        if i % 100 == 0:
            print(f"Iteration {i}: cost = {cost_history[-1]}")
    
    return theta, cost_history

# Set learning rate and iterations
learning_rate = 0.01
iterations = 1000
theta_init = np.zeros(X.shape[1] + 1)

# Add bias term to X
X_b = np.c_[np.ones((X.shape[0], 1)), X]

# Run gradient descent
theta, cost_history = gradient_descent(X_b, y, theta_init, learning_rate, iterations)

# Plot cost over iterations
plt.figure(figsize=(10, 6))
plt.plot(range(iterations), cost_history, color='blue')
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.title('Cost over Iterations')
plt.show()

# Print the final linear model and cost
print(f'Final linear model: Y = {theta[0]} + {theta[1]} * X1 + {theta[2]} * X2 + {theta[3]} * X3')
print(f'Final cost: {cost_history[-1]}')

# Evaluate impact of different learning rates
learning_rates = [0.1, 0.05, 0.01]
theta_learning_rates = []
cost_learning_rates = []

for lr in learning_rates:
    theta_lr, cost_lr = gradient_descent(X_b, y, theta_init.copy(), lr, iterations)
    theta_learning_rates.append(theta_lr)
    cost_learning_rates.append(cost_lr)

# Plot cost over iterations for different learning rates
plt.figure(figsize=(10, 6))

for i, lr in enumerate(learning_rates):
    plt.plot(range(iterations), cost_learning_rates[i], label=f'LR = {lr}')

plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.title('Cost over Iterations for different Learning Rates')
plt.legend()
plt.show()

# Print impact of different learning rates on the final loss
print("Impact of different learning rates on the final loss and number of training iterations:")
for i, lr in enumerate(learning_rates):
    print(f"Learning rate {lr}: Final cost = {cost_learning_rates[i][-1]}, Iterations taken = {iterations}")

# Make predictions for new values
new_values = np.array([[1, 1, 1], [2, 0, 4], [3, 2, 1]])
new_values_normalized = scaler_X.transform(new_values)
new_values_b = np.c_[np.ones((new_values_normalized.shape[0], 1)), new_values_normalized]
predictions_normalized = hypothesis(theta, new_values_b)
predictions = scaler_y.inverse_transform(predictions_normalized.reshape(-1, 1))

for i, new_val in enumerate(new_values):
    print(f"Prediction for {new_val}: {predictions[i][0]}")
